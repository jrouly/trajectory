#! /usr/bin/env python

"""
trajectory.py
Author: Jean Michel Rouly

This is the main executable file. Use it to call subcommands in the
application structure.
"""


from trajectory.clean import TARGETS as CLEAN_TARGETS
from trajectory.scrape import engines

from argparse import ArgumentParser
import trajectory.log
import sys
import os

SCRAPE_TARGETS = engines.list()

# Constant values.
# TODO: These should be read from a configuration at some point.
PROG_NAME = "Trajectory"
PROG_DESC = "This Python application is used to acquire (scrape, clean) a dataset."
PROG_VERSION = PROG_NAME + " 0.0"


def main():
    """
    Handle basic command line argument parsing & configure logging. Route
    logic depending on what the user wants to do.
    """

    # Verify that the TRJ_HOME variable is set.
    if os.environ.get("TRJ_HOME") is None:
        print("TRJ_HOME not found. Exiting.")
        sys.exit( 1 )
    else:
        HOME = os.environ.get("TRJ_HOME")


    # Create top-level command line argument parser.
    parser = ArgumentParser(description=PROG_DESC, prog=PROG_NAME)
    parser.add_argument("--version", action="version", version=PROG_VERSION)
    parser.add_argument("--logging-dir", help="log storage directory",
            default=os.path.join(HOME, "logs"))
    parser.add_argument("--data-dir", help="data storage directory",
            default=os.path.join(HOME, "data"))


    # Specify subcommands using a subparser.
    subparsers = parser.add_subparsers(title="subcommands",
            dest="subparser_name",
            description="valid subcommands to run",
            help="indicate which subcommand to run")


    # Create parser for "scrape" command.
    parser_scrape = subparsers.add_parser("scrape", help="scrape syllabi")
    parser_scrape.add_argument("targets", choices=SCRAPE_TARGETS,
            nargs="+",
            help="target websites to scrape")
    parser_scrape.add_argument("--download",
            help="download the data",
            action="store_true")
    parser_scrape.add_argument("--clean",
            help="clean the already downloaded data",
            action="store_true")


    # Create parser for "cluster" command.
    parser_cluster = subparsers.add_parser("cluster", help="cluster syllabi")
    parser_cluster.add_argument("target", choices=SCRAPE_TARGETS,
            help="target syllabus pool to cluster")


    # Create parser for "clean" command.
    parser_clean = subparsers.add_parser("clean",
            description="The clean subcommand is used to clean up generated content.",
            help="clean data folders")
    parser_clean.add_argument("targets",
            choices=CLEAN_TARGETS,
            default=CLEAN_TARGETS[0],
            nargs="*",
            help="what to clean")


    # Parse command line arguments.
    args = parser.parse_args(sys.argv[1:])


    # Construct global logging object.
    log = trajectory.log.global_logger("root")


    # Start up program.
    log.info("Beginning.")


    # Execute subcommand logic.
    if args.subparser_name == "scrape":
        from trajectory.scrape import scrape
        scrape( args )
    elif args.subparser_name == "clean":
        from trajectory import clean
        clean( args )
    elif args.subparser_name == "cluster":
        from trajectory import cluster
        # TODO: Fix this up to use your stackmining infrastructure.
        cluster( args )
    else:
        log.warn("You did not provide a command.")

    # Exit the program.
    log.info("Exiting.")
    sys.exit( 0 )


if __name__ == '__main__':
    main()
