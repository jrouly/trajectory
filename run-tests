#!/bin/bash

##################################################
# Initialization

# Document-topic similarity.
# Defaults to number of topics.
alpha_values="1 10 100 500 1000"

# Document-word similarity.
# Defaults to 0.01.
beta_values="0.0001 0.001 0.01 0.1 0.5 1.0"

# Number of topics to infer.
topic_values="100 250 500 750 1000"

# Number of iterations to run.
iter_values="3000"

# Initialize run counter.
run=1

##################################################
# Environment setup

# Check for errors.
set +e

# Create results directory.
rm -rf results
mkdir -p results logs

# Create backup database.
cp data.db data.db.bkp

##################################################
# Execution

# Iterate through values.
for alpha in $alpha_values; do
for beta in $beta_values; do
for topics in $topic_values; do
for iter in $iter_values; do

  # Print run information.
  date +%Y.%m.%d.%H.%M.%S
  echo "> run: $run"
  echo "> alpha: $alpha"
  echo "> beta: $beta"
  echo "> topics: $topics"
  echo "> iter: $iter"

  # Learn.
  echo "Learning."
  bin/learn -threads 8 \
            -iterations $iter \
            -alpha $alpha \
            -beta $beta \
            -topics $topics \
            -words 10 \
            -in data \
            -out results &>> "logs/learn-$run.log"

  # Read in results.
  echo "Importing results."
  bin/scrape import-results \
            --topic-file results/*/topics.csv \
            --course-file results/*/documents.csv \
            --alpha $alpha --beta $beta --iterations $iter

  if [[ $? != 0 ]]; then
    echo "> Error during learning step of experiment."
    run=$((run + 1))
    continue
  fi

  # Remove old results.
  rm -rf results/*

  run=$((run + 1))

done
done
done
done | tee -a run-tests.log

exit
